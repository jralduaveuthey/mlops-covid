{"cells":[{"cell_type":"markdown","metadata":{"id":"vPeecVCfKURM"},"source":["# Notebook for experiment tracking\n","## Store remote everything\n","MLflow original setup:\n","* Tracking server: hosted in a container in Fargate.\n","* Backend store:  Amazon RDS database.\n","* Artifacts store: S3 bucket.\n","\n","The interaction with MLflow is usually made in training jobs, data scientists evaluating their experiments, or APIs that expose our models. In this case the tracking server URI is online so everyone with a username and password can access to it. Since it is running on Docker (in Fargate) it can be taken down when noone is using it. The information will not be lost since the ML models will be stored as artifacts in a S3 bucket and in RDS the MLflow Tracking Server will store experiment and run metadata as well as params, metrics, and tags for runs\n","\n","To run this you need to launch the mlflow server with the corresponding Github action. The `mlflow server` command is in the exp-track-mod-reg-mlflowFargate\\Dockerfile. \n","\n","The Uri for the MLflow Tracking server can be seen in the outputs from the cloudformation stack \"mlflow-server\"."]},{"cell_type":"markdown","metadata":{},"source":["--- The first parts of the notebook taken from 08-my_project/EDA/Version_1.ipynb ---"]},{"cell_type":"markdown","metadata":{},"source":["## Testing mlflow tracking server"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Fargate_tracking_uri = \"http://mlflo-mlflo-1t73jy0dxw3bw-f2c1f1638afa4ab6.elb.eu-central-1.amazonaws.com/\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import mlflow\n","mlflow.set_tracking_uri(Fargate_tracking_uri)#NOTE: Important!!!  tput the \"http://\" at the beginning or it will not work properly\n","#NOTE: Important!!!  to set the tracking uri here cause otherwise it stores the artifact locally. \n","#NOTE: Important!!! The uri wil change every time you start the tracking server on Fargate so you have to change it every time\n","print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'http://mlflo-mlflo-1t73jy0dxw3bw-f2c1f1638afa4ab6.elb.eu-central-1.amazonaws.com/'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["mlflow.get_tracking_uri()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022/12/04 18:50:26 INFO mlflow.tracking.fluent: Experiment with name 'my-experimenta' does not exist. Creating a new experiment.\n"]},{"data":{"text/plain":["<Experiment: artifact_location='s3://34aghxe-mlflow-server-artifacts-141507290110/1', creation_time=1670176225608, experiment_id='1', last_update_time=1670176225608, lifecycle_stage='active', name='my-experimenta', tags={}>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["mlflow.set_experiment(\"my-experimenta\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["[<Experiment: artifact_location='s3://34aghxe-mlflow-server-artifacts-141507290110/1', creation_time=1670176225608, experiment_id='1', last_update_time=1670176225608, lifecycle_stage='active', name='my-experimenta', tags={}>,\n"," <Experiment: artifact_location='s3://34aghxe-mlflow-server-artifacts-141507290110/0', creation_time=1670175501589, experiment_id='0', last_update_time=1670175501589, lifecycle_stage='active', name='Default', tags={}>]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from  mlflow.tracking import MlflowClient\n","client = MlflowClient()\n","experiments = client.search_experiments() # returns a list of mlflow.entities.Experiment\n","experiments"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mlflow.end_run() #NOTE: Important to end the run after setting the experiment in mlflow 2.0.1. Otherwise it does not work"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["experiments\n","run = client.create_run(experiments[0].experiment_id) # returns mlflow.entities.Run\n","client.log_param(run.info.run_id, \"hello\", \"world\")\n","client.set_terminated(run.info.run_id)"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libs"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from datetime import timedelta, datetime, timezone\n","from pandas._libs.tslibs.timestamps import Timestamp\n","import pandas as pd\n","import numpy as np\n","import mlflow\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"markdown","metadata":{},"source":["## Get and prepare data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["LAST_DAYS = 30 #Number of days to get data from\n","\n","now = datetime.now()\n","\n","dfs = []  # empty list which will hold your dataframes\n","df_temp_2 = pd.DataFrame()\n","for d in range(1, LAST_DAYS): #NOTE: do the same that has been done for the first day but for the whole period\n","    date = now - timedelta(days=d)\n","    date_str = date.strftime(\"%m-%d-%Y\")\n","    # print(date_str)\n","    source_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/' + date_str + '.csv'\n","    df_temp = pd.read_csv(source_url)\n","    df_temp.rename(columns={\"Last_Update\": \"Date\"}, inplace=True) #Renane dataframe column from \"Last_Update\" to \"Date\"\n","    df_temp_2 = df_temp[[\"Admin2\", \"Province_State\", \"Country_Region\",\"Confirmed\", \"Deaths\"]] #TODO: consider also other columns in future versions like Recovered,Active,Combined_Key,Incident_Rate,Case_Fatality_Ratio\n","    df_temp_2[\"Date\"] = date.strftime(\"%Y-%m-%d\") #TODO: fix this so that no warning comes\n","    dfs.append(df_temp_2)  # append dataframe to list\n","    \n","res = pd.concat(dfs, ignore_index=True)  # concatenate list of dataframes\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# group by Country_Region and sum Confirmed and Deaths\n","df = res.groupby(['Province_State','Country_Region','Date']).agg({'Confirmed':'sum', 'Deaths':'sum'})\n","df.reset_index(inplace=True)\n","df.rename(columns={\"Confirmed\": \"ConfirmedCases\", \"Deaths\": \"Fatalities\"}, inplace=True)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["## Prepare train(dev)-test set\n","loc_group = [\"Province_State\", \"Country_Region\"]\n","def preprocess(df):\n","    df[\"Date\"] = df[\"Date\"].astype(\"datetime64[ms]\")\n","    for col in loc_group:\n","        df[col].fillna(\"none\", inplace=True) #NOTE: replace all NaN with none\n","    return df\n","df = preprocess(df)\n","\n","TARGETS = [\"ConfirmedCases\", \"Fatalities\"]\n","for col in TARGETS:\n","    df[col] = np.log1p(df[col]) \n","    \n","for col in TARGETS:\n","    df[\"prev_{}\".format(col)] = df.groupby(loc_group)[col].shift() #NOTE: the prev_ columns basically has the same than the others but delayed one day\n","    \n","    \n","df = df[df[\"Date\"] > df[\"Date\"].min()].copy() #NOTE: removes the first day since it has NaNs in the \"prev\" columns\n","\n","TEST_DAYS = 7 #Number of days to test the model\n","TEST_FIRST = now - timedelta(days=TEST_DAYS)\n","TEST_FIRST = TEST_FIRST.replace(hour=0, minute=0, second=0, microsecond=0)\n","TEST_FIRST = Timestamp(TEST_FIRST)\n","\n","dev_df, test_df = df[df[\"Date\"] < TEST_FIRST].copy(), df[df[\"Date\"] >= TEST_FIRST].copy() #I am testing the model with the predictions of the last 7 (TEST_DAYS) days and\n","                                                                                          # training it with data from the previous 30 days (LAST_DAYS) excluding the last 7 days (TEST_DAYS)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["features = [\"prev_{}\".format(col) for col in TARGETS]"]},{"cell_type":"markdown","metadata":{},"source":["## Modeling"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["#TODO: fix the UserWarnings that appear when running this cell\n","\n","def rmse(y_true, y_pred):\n","    return np.sqrt(mean_squared_error(y_true, y_pred))\n","\n","def evaluate(df):\n","    error = 0\n","    for col in TARGETS:\n","        error += rmse(df[col].values, df[\"pred_{}\".format(col)].values) #NOTE: checks the error between the predicted columns and the target columns\n","    return np.round(error/len(TARGETS), 5)\n","\n","\n","def predict(test_df, first_day, num_days, val=False):\n","    y_pred = np.clip(model.predict(test_df.loc[test_df[\"Date\"] == first_day][features]), None, 16)#NOTE: here he is predicting the targets for the first day and \n","                                                                                                    #saturating (clip) them with max=16\n"," \n","    for i, col in enumerate(TARGETS):\n","        test_df[\"pred_{}\".format(col)] = 0\n","        test_df.loc[test_df[\"Date\"] == first_day, \"pred_{}\".format(col)] = y_pred[:, i] #NOTE: here he sets the predicted columns\n","\n","    if val:\n","        print(first_day, evaluate(test_df[test_df[\"Date\"] == first_day])) #NOTE: print the date of the first day and the error between the predicted targets and the real targets\n","\n","    for d in range(1, num_days): #NOTE: do the same that has been done for the first day but for the whole period\n","        y_pred = np.clip(model.predict(y_pred), None, 16)\n","        date = first_day + timedelta(days=d)\n","\n","        for i, col in enumerate(TARGETS):\n","            test_df.loc[test_df[\"Date\"] == date, \"pred_{}\".format(col)] = y_pred[:, i]\n","\n","        if val:\n","            print(date, evaluate(test_df[test_df[\"Date\"] == date])) #NOTE: when we see all the errors we can see that the farther the date from the first day the higher the error\n","        \n","    return test_df"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tracking URI: 's3://34aghxe-mlflow-server-artifacts-141507290110/1/bd34cf1e96834b99b18158f38e75ae88/artifacts'\n"]}],"source":["print(f\"tracking URI: '{mlflow.get_artifact_uri()}'\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022/12/04 18:54:14 INFO mlflow.tracking.fluent: Experiment with name 'experiment-covid-3' does not exist. Creating a new experiment.\n"]},{"name":"stdout","output_type":"stream","text":["2022-11-27 00:00:00 0.02348\n","2022-11-28 00:00:00 0.09259\n","2022-11-29 00:00:00 0.0594\n","2022-11-30 00:00:00 0.04808\n","2022-12-01 00:00:00 0.24874\n","2022-12-02 00:00:00 0.24907\n","2022-12-03 00:00:00 0.25331\n","RMSE: 0.17062\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n","  warnings.warn(\"Setuptools is replacing distutils.\")\n"]},{"name":"stdout","output_type":"stream","text":["Artifacts URI: 's3://34aghxe-mlflow-server-artifacts-141507290110/2/0c2df617d52d47a08f3f840daffc19a9/artifacts'\n"]}],"source":["mlflow.set_experiment(\"experiment-covid-3\") \n","\n","with mlflow.start_run():\n","    \n","    degree_poly = 2\n","    incl_bias = False\n","    mlflow.log_param('degree_poly', degree_poly)\n","    mlflow.log_param('include_bias', incl_bias)\n","    \n","    model = Pipeline([('poly', PolynomialFeatures(degree=degree_poly, include_bias=incl_bias)),\n","                  ('linear', LinearRegression())])\n","    \n","    model.fit(dev_df[features], dev_df[TARGETS])\n","    [mean_squared_error(dev_df[TARGETS[i]], model.predict(dev_df[features])[:, i]) for i in range(len(TARGETS))] #NOTE: check the mean_squared_error from the training dataset\n","    \n","    test_df = predict(test_df, TEST_FIRST, TEST_DAYS, val=True) #NOTE: makes predictions \n","    #for TEST_DAYS number of days ...just to print it on the screen\n","    \n","    eval_RMSE = evaluate(test_df) #NOTE: the error of all the predictions\n","    print(\"RMSE:\", eval_RMSE)\n","    mlflow.log_metric(\"evaluated_RMSE\", eval_RMSE)\n","\n","    mlflow.sklearn.log_model(model, artifact_path=\"models\")\n","    print(f\"Artifacts URI: '{mlflow.get_artifact_uri()}'\") #returns where the model is stored\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["mlflow.end_run()"]},{"cell_type":"markdown","metadata":{},"source":["I see in mlflow ui that the RUNID for this experiment is 6509bec6c96d4f9d8e1b88c0812e1590"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022/12/04 18:56:05 INFO mlflow.tracking.fluent: Experiment with name 'experiment-covid-2' does not exist. Creating a new experiment.\n"]},{"name":"stdout","output_type":"stream","text":["2022-11-27 00:00:00 0.02392\n","2022-11-28 00:00:00 0.09341\n","2022-11-29 00:00:00 0.06126\n","2022-11-30 00:00:00 0.05069\n","2022-12-01 00:00:00 0.25114\n","2022-12-02 00:00:00 0.25199\n","2022-12-03 00:00:00 0.25664\n","RMSE: 0.1727\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n","c:\\Users\\jraldua-veuthey\\.virtualenvs\\mlops-covid-0dX7y8J5\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but PolynomialFeatures was fitted with feature names\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["default artifacts URI: 's3://34aghxe-mlflow-server-artifacts-141507290110/3/6509bec6c96d4f9d8e1b88c0812e1590/artifacts'\n"]}],"source":["#NOTE: here UI change the degree_poly to have another experiment\n","mlflow.set_experiment(\"experiment-covid-2\") \n","\n","with mlflow.start_run(): \n","    \n","    degree_poly = 3\n","    incl_bias = False\n","    mlflow.log_param('degree_poly', degree_poly)\n","    mlflow.log_param('include_bias', incl_bias)\n","    \n","    model = Pipeline([('poly', PolynomialFeatures(degree=degree_poly, include_bias=incl_bias)),\n","                  ('linear', LinearRegression())])\n","    \n","    model.fit(dev_df[features], dev_df[TARGETS])\n","    [mean_squared_error(dev_df[TARGETS[i]], model.predict(dev_df[features])[:, i]) for i in range(len(TARGETS))] #NOTE: check the mean_squared_error from the training dataset\n","    \n","    test_df = predict(test_df, TEST_FIRST, TEST_DAYS, val=True) #NOTE: makes predictions \n","    #for TEST_DAYS number of days ...just to print it on the screen\n","    \n","    eval_RMSE = evaluate(test_df) #NOTE: the error of all the predictions\n","    print(\"RMSE:\", eval_RMSE)\n","    mlflow.log_metric(\"evaluated_RMSE\", eval_RMSE)\n","\n","    mlflow.sklearn.log_model(model, artifact_path=\"models\")\n","    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\") #returns where the model is stored\n","    "]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["mlflow.end_run()"]},{"cell_type":"markdown","metadata":{},"source":["I see in mlflow ui that the RUNID for this experiment is 0c2df617d52d47a08f3f840daffc19a9"]},{"cell_type":"markdown","metadata":{},"source":["Comparing the experiments in mlflow the first one has less evaluated RSME so I will choose that model => RUNID = 6509bec6c96d4f9d8e1b88c0812e1590\n","This will also be more in detail in exp-track-mod-reg-mlflowFargate\\model-registry.ipynb"]}],"metadata":{"colab":{"collapsed_sections":["lx0eEn2mDsYw"],"name":"my_Titanic.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('mlops-covid-0dX7y8J5')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"vscode":{"interpreter":{"hash":"8af9ad7548836a0a62ae078825fd815a40e250b6c42b6752f16c38da6216742c"}}},"nbformat":4,"nbformat_minor":0}
