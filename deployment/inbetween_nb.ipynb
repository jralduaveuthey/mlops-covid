{"cells":[{"cell_type":"markdown","metadata":{"id":"vPeecVCfKURM"},"source":["# Notebook pre script\n","This is an in-between notebook. \n","Starts from exp-track-mod-reg/model-registry.ipynb so it can be later transformed to a script calling:\n","\n","`jupyter nbconvert --to script my_score.ipynb`\n","\n","The grouping everything in functions was more or less already done in exp-track-mod-reg/model-registry.ipynb\n"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libs"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","import pandas as pd\n","import numpy as np\n","from datetime import timedelta, datetime, date\n","from pandas._libs.tslibs.timestamps import Timestamp\n","import mlflow\n","import os\n"]},{"cell_type":"markdown","metadata":{},"source":["## Functions"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["TARGETS = [\"ConfirmedCases\", \"Fatalities\"]\n","features = [\"prev_{}\".format(col) for col in TARGETS]\n","loc_group = [\"Province_State\", \"Country_Region\"]\n","Province_State =\"Madrid\"\n","\n","today = date.today()\n","year = today.year\n","month = today.month\n","day = today.day\n","\n","# output_file = f'output/{Province_State}_predictons_{year:04d}-{month:02d}-{day:02d}.csv'\n","output_file = f's3://covid-predictons-jaime/{Province_State}_predictons_{year:04d}-{month:02d}-{day:02d}.csv'\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["'s3://covid-predictons-jaime/Madrid_predictons_2022-08-14.csv'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["output_file"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["MLFLOW_TRACKING_URI = 'http://127.0.0.1:5000'\n","mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n","RUN_ID = os.getenv('RUN_ID','16082a31f2be4eadb6f368b4ded2d309') #NOTE: to use this you have to run in the terminal before <export RUN_ID='16082a31f2be4eadb6f368b4ded2d309'>, otherwise you get an error when loading the model\n","RUN_ID = '16082a31f2be4eadb6f368b4ded2d309'"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def preprocess(df):\n","    df[\"Date\"] = df[\"Date\"].astype(\"datetime64[ms]\")\n","    for col in loc_group:\n","        df[col].fillna(\"none\", inplace=True) #NOTE: replace all NaN with none  \n","    for col in TARGETS:\n","        df[col] = np.log1p(df[col]) \n","    for col in TARGETS:\n","        df[\"prev_{}\".format(col)] = df.groupby(loc_group)[col].shift() #NOTE: the prev_ columns basically has the same than the others but delayed one day\n","    return df\n","\n","def create_output(df): #To have the same format as the original input\n","    for col in TARGETS:\n","        df[\"pred_out_{}\".format(col)] = np.expm1(df[\"pred_{}\".format(col)])\n","    return  df\n","\n","def get_data_last_days(num_days): #gets the data from the last \"num_days\" days\n","    num_days = num_days + 2 #I do this because I get rid of the first date since it has NaNs in the columns prev_ConfirmedCases\tprev_Fatalities and because of the for loop with range\n","    dfs = []  # empty list which will hold your dataframes\n","    for d in range(1, num_days): #NOTE: do the same that has been done for the first day but for the whole period\n","        date = datetime.now() - timedelta(days=d)\n","        date_str = date.strftime(\"%m-%d-%Y\")\n","        source_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/' + date_str + '.csv'\n","        df_temp = pd.read_csv(source_url)\n","        df_temp.rename(columns={\"Last_Update\": \"Date\"}, inplace=True) #Renane dataframe column from \"Last_Update\" to \"Date\"\n","        df_temp_2 = df_temp[[\"Admin2\", \"Province_State\", \"Country_Region\",\"Confirmed\", \"Deaths\"]].copy() #TODO: consider also other columns in future versions like Recovered,Active,Combined_Key,Incident_Rate,Case_Fatality_Ratio\n","        df_temp_2.loc[:,\"Date\"] = date.strftime(\"%Y-%m-%d\") \n","        dfs.append(df_temp_2)  # append dataframe to list\n","    res = pd.concat(dfs, ignore_index=True)  # concatenate list of dataframes\n","    \n","    # group by Country_Region and sum Confirmed and Deaths\n","    df = res.groupby(['Province_State','Country_Region','Date']).agg({'Confirmed':'sum', 'Deaths':'sum'})\n","    df.reset_index(inplace=True)\n","    df.rename(columns={\"Confirmed\": \"ConfirmedCases\", \"Deaths\": \"Fatalities\"}, inplace=True)\n","        \n","    df = preprocess(df)\n","    \n","    df = df[df[\"Date\"] > df[\"Date\"].min()].copy() #removes the first day since it has NaNs in the \"prev\" columns\n","\n","    df.reset_index(inplace=True, drop=True)\n","    \n","    return df\n","\n","def predict_today_Province_State(model,Province_State,df):\n","    y_pred = predict_today_world(model) #Predict today worldwide\n","    index_PS = df[df['Province_State']==Province_State].iloc[0].name\n","    predictions = y_pred[index_PS]\n","    return predictions #First the predicted Confirmed cases and second the predicted fatalities\n","\n","def predict_today_world(model):#Does the prediction for today\n","    df = get_data_last_days(1) #Get data from yesterday\n","    yesterday = datetime.now() - timedelta(days=1)\n","    yesterday = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)\n","    yesterday = Timestamp(yesterday)\n","    y_pred = np.clip(model.predict(df.loc[df[\"Date\"] == yesterday][features]), None, 16)#NOTE: here predicting the targets for the first day and saturating (clip) them with max=16\n","    return y_pred\n","\n","def evaluate_yesterday():\n","    return evaluate_last_days(1)\n","\n","def rmse(y_true, y_pred):\n","    return np.sqrt(mean_squared_error(y_true, y_pred))\n","\n","def predict_past(model, num_days):\n","    test_df = get_data_last_days(num_days)\n","    first_day = datetime.now() - timedelta(days=num_days)\n","    first_day = first_day.replace(hour=0, minute=0, second=0, microsecond=0)\n","    first_day = Timestamp(first_day)\n","    y_pred = np.clip(model.predict(test_df.loc[test_df[\"Date\"] == first_day][features]), None, 16)#NOTE: here he is predicting the targets for the first day and saturating (clip) them with max=16\n","    for i, col in enumerate(TARGETS):\n","        test_df[\"pred_{}\".format(col)] = 123\n","        test_df.loc[test_df[\"Date\"] == first_day, \"pred_{}\".format(col)] = y_pred[:, i] #NOTE: here he sets the predicted column\n","    for d in range(1, num_days): #NOTE: do the same that has been done for the first day but for the whole period\n","        y_pred = np.clip(model.predict(y_pred), None, 16)\n","        date = first_day + timedelta(days=d)\n","        for i, col in enumerate(TARGETS):\n","            test_df.loc[test_df[\"Date\"] == date, \"pred_{}\".format(col)] = y_pred[:, i]\n","        \n","    test_df = create_output(test_df)\n","    return test_df\n","\n","def evaluate_last_days(model,num_days):\n","    #get data from the last \"num_days\" days\n","    df = predict_past(model,num_days)\n","    \n","    #get the rmse\n","    error = 0\n","    for col in TARGETS:\n","        error += rmse(df[col].values, df[\"pred_{}\".format(col)].values) #NOTE: checks the error between the predicted columns and the target columns\n","    return np.round(error/len(TARGETS), 5)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def load_model(run_id):\n","    logged_model = f's3://mlflow-artifacts-remote-jaime/4/{run_id}/artifacts/models'\n","    model = mlflow.pyfunc.load_model(logged_model)\n","    return model\n","\n","def apply_model_today_Province_State(run_id, output_file): #NOTE: this sequence is only for the function predict_today_Province_State, \n","                                                    #other functions not separated into \"tasks\" (meaning functions call each other like inside predict_past it calls get_data_last_days)\n","    print(f\">>>>>>>>>>>>>>>>>> Getting COVID data from yesterday from CSSE at Johns Hopkins University's Github ...\")\n","    df = get_data_last_days(1) #Get data from yesterday\n","\n","    print(f'>>>>>>>>>>>>>>>>>> Loading the model with RUN_ID={run_id}...')\n","    model = load_model(run_id)\n","\n","    print(f'>>>>>>>>>>>>>>>>>> Applying the model...')\n","    predictions = predict_today_Province_State(model,Province_State,df) #Returns first the predicted Confirmed cases and second the predicted fatalities\n","\n","    print(f'>>>>>>>>>>>>>>>>>> Saving the result to {output_file}...')\n","    df_result = pd.DataFrame()\n","    df_result['Province_State'] = pd.Series(Province_State)\n","    df_result['Date'] =  pd.Series(today)\n","    df_result['pred_out_ConfirmedCases']=pd.Series(np.expm1(predictions[0])) #TODO: instead of doing the exp here, call create_output inside the pred_today_* functions\n","    df_result['pred_out_Fatalities']=pd.Series(np.expm1(predictions[1])) #TODO: instead of doing the exp here, call create_output inside the pred_today_* functions\n","    df_result['model_version'] = run_id\n","    # df_result.to_parquet(output_file, index=False)\n","    df_result.to_csv(output_file, index=False)\n","    \n","    print(f'>>>>>>>>>>>>>>>>>> Finished succesfully!')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[">>>>>>>>>>>>>>>>>> Getting COVID data from yesterday from CSSE at Johns Hopkins University's Github ...\n",">>>>>>>>>>>>>>>>>> Loading the model with RUN_ID=16082a31f2be4eadb6f368b4ded2d309...\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m apply_model_today_Province_State(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     run_id\u001b[39m=\u001b[39;49mRUN_ID,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     output_file\u001b[39m=\u001b[39;49moutput_file\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m )\n","\u001b[1;32m/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb Cell 10\u001b[0m in \u001b[0;36mapply_model_today_Province_State\u001b[0;34m(run_id, output_file)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m df \u001b[39m=\u001b[39m get_data_last_days(\u001b[39m1\u001b[39m) \u001b[39m#Get data from yesterday\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m>>>>>>>>>>>>>>>>>> Loading the model with RUN_ID=\u001b[39m\u001b[39m{\u001b[39;00mrun_id\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(run_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m>>>>>>>>>>>>>>>>>> Applying the model...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m predictions \u001b[39m=\u001b[39m predict_today_Province_State(model,Province_State,df) \u001b[39m#Returns first the predicted Confirmed cases and second the predicted fatalities\u001b[39;00m\n","\u001b[1;32m/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb Cell 10\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(run_id)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(run_id):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     logged_model \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms3://mlflow-artifacts-remote-jaime/4/\u001b[39m\u001b[39m{\u001b[39;00mrun_id\u001b[39m}\u001b[39;00m\u001b[39m/artifacts/models\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     model \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39;49mpyfunc\u001b[39m.\u001b[39;49mload_model(logged_model)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmlops-zoomcamp-eu-central-1b/home/ubuntu/mlops-zoomcamp/08-my_project/deployment/inbetween_nb.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n","File \u001b[0;32m~/.local/share/virtualenvs/08-my_project-6zcrQ2k9/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:737\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\n\u001b[1;32m    712\u001b[0m     model_uri: \u001b[39mstr\u001b[39m, suppress_warnings: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, dst_path: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PyFuncModel:\n\u001b[1;32m    714\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m    Load a model stored in Python function format.\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[39m                     path will be created.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m     local_path \u001b[39m=\u001b[39m _download_artifact_from_uri(artifact_uri\u001b[39m=\u001b[39;49mmodel_uri, output_path\u001b[39m=\u001b[39;49mdst_path)\n\u001b[1;32m    739\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m suppress_warnings:\n\u001b[1;32m    740\u001b[0m         _warn_dependency_requirement_mismatches(local_path)\n","File \u001b[0;32m~/.local/share/virtualenvs/08-my_project-6zcrQ2k9/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:100\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m:param artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39m                    a local output path will be created.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m root_uri, artifact_path \u001b[39m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[0;32m--> 100\u001b[0m \u001b[39mreturn\u001b[39;00m get_artifact_repository(artifact_uri\u001b[39m=\u001b[39;49mroot_uri)\u001b[39m.\u001b[39;49mdownload_artifacts(\n\u001b[1;32m    101\u001b[0m     artifact_path\u001b[39m=\u001b[39;49martifact_path, dst_path\u001b[39m=\u001b[39;49moutput_path\n\u001b[1;32m    102\u001b[0m )\n","File \u001b[0;32m~/.local/share/virtualenvs/08-my_project-6zcrQ2k9/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repo.py:258\u001b[0m, in \u001b[0;36mArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mfor\u001b[39;00m inflight_download \u001b[39min\u001b[39;00m inflight_downloads:\n\u001b[1;32m    257\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 258\u001b[0m         inflight_download\u001b[39m.\u001b[39;49mdownload_future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    259\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    260\u001b[0m         failed_downloads[inflight_download\u001b[39m.\u001b[39msrc_artifact_path] \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(e)\n","File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n","File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["apply_model_today_Province_State(\n","    run_id=RUN_ID,\n","    output_file=output_file\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["lx0eEn2mDsYw"],"name":"my_Titanic.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.4 ('08-my_project-6zcrQ2k9')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"7fde853788301886b8fed61f068d574e1d63c7368ed08973156a22dfdab1a95e"}}},"nbformat":4,"nbformat_minor":0}
